{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb32a80-0e1b-4ddf-b2ff-1fe20611345b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e496b5c5-b8f1-40b3-821c-ed62af8f54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ast\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import neptune\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "\n",
    "from src.pytorch_faster_rcnn_tutorial.backbone_resnet import ResNetBackbones\n",
    "from src.pytorch_faster_rcnn_tutorial.datasets import (\n",
    "    ObjectDetectionDataSet,\n",
    "    ObjectDetectionDatasetSingle,\n",
    ")\n",
    "from src.pytorch_faster_rcnn_tutorial.faster_RCNN import get_faster_rcnn_resnet\n",
    "from src.pytorch_faster_rcnn_tutorial.transformations import (\n",
    "    ComposeDouble,\n",
    "    ComposeSingle,\n",
    "    FunctionWrapperDouble,\n",
    "    FunctionWrapperSingle,\n",
    "    apply_nms,\n",
    "    apply_score_threshold,\n",
    "    normalize_01,\n",
    ")\n",
    "from src.pytorch_faster_rcnn_tutorial.utils import (\n",
    "    collate_single,\n",
    "    get_filenames_of_path,\n",
    "    save_json,\n",
    ")\n",
    "from src.pytorch_faster_rcnn_tutorial.viewers.object_detection_viewer import (\n",
    "    ObjectDetectionViewer,\n",
    "    ObjectDetectionViewerSingle,\n",
    ")\n",
    "from training_script import NeptuneSettings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f582ef-cf8b-4ddd-bfce-e986bfa6a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {\n",
    "    \"EXPERIMENT\": \"HEAD-51\",  # experiment name, e.g. Head-42\n",
    "    \"OWNER\": \"john-judge\",  # e.g. johndoe55\n",
    "    \"INPUT_DIR\": \"src/pytorch_faster_rcnn_tutorial/data/heads/test\",  # files to predict\n",
    "    \"PREDICTIONS_PATH\": \"predictions\",  # where to save the predictions\n",
    "    \"MODEL_DIR\": \"heads\",  # load model from checkpoint\n",
    "    \"DOWNLOAD\": True,  # whether to download from neptune\n",
    "    \"DOWNLOAD_PATH\": \"model\",  # where to save the model if DOWNLOAD is True\n",
    "    \"PROJECT\": \"Heads\",  # Project name\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f8bab4-464b-480b-883e-3e8e5e267ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-27 18:09:40 - INFO - utils.py:27:get_filenames_of_path - Found 5 files in src\\pytorch_faster_rcnn_tutorial\\data\\heads\\test\n"
     ]
    }
   ],
   "source": [
    "# input files\n",
    "inputs = get_filenames_of_path(pathlib.Path(params[\"INPUT_DIR\"]))\n",
    "inputs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c30ad2-9fd9-4090-b300-78a36fe83ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "transforms = ComposeSingle(\n",
    "    [\n",
    "        FunctionWrapperSingle(np.moveaxis, source=-1, destination=0),\n",
    "        FunctionWrapperSingle(normalize_01),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f296e5-971c-40bc-a7ae-cdb3f110ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dataset = ObjectDetectionDatasetSingle(\n",
    "    inputs=inputs,\n",
    "    transform=transforms,\n",
    "    use_cache=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e02b562-62e3-42a1-abbd-892c3b77f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "dataloader_prediction = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_single,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe76faa4-35aa-4851-8a6d-91f601f425f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment variables (pydantic BaseSettings class)\n",
    "neptune_settings: NeptuneSettings = NeptuneSettings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618796d3-1009-42ce-8fbc-4e8197a652ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProjectNotFound",
     "evalue": "\n\n----ProjectNotFound-------------------------------------------------------------------------\n\nProject jjudge3/Heads not found.\n\nVerify if your project's name was not misspelled. You can find proper name after logging into Neptune UI.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPNotFound\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\neptune\\internal\\api_clients\\hosted_api_clients\\hosted_backend_api_client.py:149\u001b[0m, in \u001b[0;36mHostedNeptuneBackendApiClient.get_project\u001b[1;34m(self, project_qualified_name)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend_swagger_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetProject\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprojectIdentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_qualified_name\u001b[49m\n\u001b[1;32m--> 149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     warning \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Server-Warning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\bravado\\http_future.py:200\u001b[0m, in \u001b[0;36mHttpFuture.response\u001b[1;34m(self, timeout, fallback_result, exceptions_to_catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m request_end_time \u001b[38;5;241m=\u001b[39m monotonic\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 200\u001b[0m swagger_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_swagger_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincoming_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m incoming_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\bravado\\http_future.py:124\u001b[0m, in \u001b[0;36mreraise_errors.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m connection_errors \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\bravado\\http_future.py:300\u001b[0m, in \u001b[0;36mHttpFuture._get_swagger_result\u001b[1;34m(self, incoming_response)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m     \u001b[43munmarshal_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincoming_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m     swagger_result \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mcast(T, incoming_response\u001b[38;5;241m.\u001b[39mswagger_result)\n",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\bravado\\http_future.py:353\u001b[0m, in \u001b[0;36munmarshal_response\u001b[1;34m(incoming_response, operation, response_callbacks)\u001b[0m\n\u001b[0;32m    351\u001b[0m         response_callback(incoming_response, operation)\n\u001b[1;32m--> 353\u001b[0m \u001b[43mraise_on_expected\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincoming_response\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\bravado\\http_future.py:420\u001b[0m, in \u001b[0;36mraise_on_expected\u001b[1;34m(http_response)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m http_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m make_http_exception(\n\u001b[0;32m    421\u001b[0m         response\u001b[38;5;241m=\u001b[39mhttp_response,\n\u001b[0;32m    422\u001b[0m         swagger_result\u001b[38;5;241m=\u001b[39mhttp_response\u001b[38;5;241m.\u001b[39mswagger_result)\n",
      "\u001b[1;31mHTTPNotFound\u001b[0m: 404 Not Found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProjectNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import experiment from neptune\u001b[39;00m\n\u001b[0;32m      2\u001b[0m project_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOWNER\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROJECT\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m project \u001b[38;5;241m=\u001b[39m \u001b[43mneptune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_qualified_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI2Yjg2Y2E2Ny0yMWJkLTRjMjEtODNlNS01NjQwYjNjNDg1MWQifQ==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# get project\u001b[39;00m\n\u001b[0;32m      6\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXPERIMENT\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# experiment id\u001b[39;00m\n\u001b[0;32m      7\u001b[0m experiment \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mget_experiments(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mexperiment_id)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\neptune\\__init__.py:185\u001b[0m, in \u001b[0;36minit\u001b[1;34m(project_qualified_name, api_token, proxies, backend, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     backend \u001b[38;5;241m=\u001b[39m backend_factory(\n\u001b[0;32m    179\u001b[0m         backend_name\u001b[38;5;241m=\u001b[39mbackend_name,\n\u001b[0;32m    180\u001b[0m         api_token\u001b[38;5;241m=\u001b[39mapi_token,\n\u001b[0;32m    181\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    184\u001b[0m session \u001b[38;5;241m=\u001b[39m Session(backend\u001b[38;5;241m=\u001b[39mbackend)\n\u001b[1;32m--> 185\u001b[0m project \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_qualified_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m project\n",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\neptune\\sessions.py:173\u001b[0m, in \u001b[0;36mSession.get_project\u001b[1;34m(self, project_qualified_name)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a project with given ``project_qualified_name``.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03mIn order to access experiments data one needs to get a :class:`~neptune.projects.Project` object first.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    171\u001b[0m project_qualified_name \u001b[38;5;241m=\u001b[39m assure_project_qualified_name(project_qualified_name)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_qualified_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\neptune\\utils.py:253\u001b[0m, in \u001b[0;36mwith_api_exceptions_handler.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retry \u001b[38;5;241m<\u001b[39m retries:\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 253\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mSSLError:\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NeptuneSSLVerificationError()\n",
      "File \u001b[1;32mc:\\Users\\jjudge3\\Anaconda3\\envs\\faster-rcnn-tutorial\\lib\\site-packages\\neptune\\internal\\api_clients\\hosted_api_clients\\hosted_backend_api_client.py:162\u001b[0m, in \u001b[0;36mHostedNeptuneBackendApiClient.get_project\u001b[1;34m(self, project_qualified_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Project(\n\u001b[0;32m    156\u001b[0m         backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_leaderboard_backend(project\u001b[38;5;241m=\u001b[39mproject),\n\u001b[0;32m    157\u001b[0m         internal_id\u001b[38;5;241m=\u001b[39mproject\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    158\u001b[0m         namespace\u001b[38;5;241m=\u001b[39mproject\u001b[38;5;241m.\u001b[39morganizationName,\n\u001b[0;32m    159\u001b[0m         name\u001b[38;5;241m=\u001b[39mproject\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPNotFound:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProjectNotFound(project_qualified_name)\n",
      "\u001b[1;31mProjectNotFound\u001b[0m: \n\n----ProjectNotFound-------------------------------------------------------------------------\n\nProject jjudge3/Heads not found.\n\nVerify if your project's name was not misspelled. You can find proper name after logging into Neptune UI.\n"
     ]
    }
   ],
   "source": [
    "# import experiment from neptune\n",
    "project_name = f'{params[\"OWNER\"]}/{params[\"PROJECT\"]}'\n",
    "project = neptune.init(\n",
    "    project_qualified_name=project_name, api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI2Yjg2Y2E2Ny0yMWJkLTRjMjEtODNlNS01NjQwYjNjNDg1MWQifQ==\"\n",
    ")  # get project\n",
    "experiment_id = params[\"EXPERIMENT\"]  # experiment id\n",
    "experiment = project.get_experiments(id=experiment_id)[0]\n",
    "parameters = experiment.get_parameters()\n",
    "properties = experiment.get_properties()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455a449-db53-4e14-aa41-e2192ce719a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcnn transform\n",
    "transform = GeneralizedRCNNTransform(\n",
    "    min_size=int(parameters[\"MIN_SIZE\"]),\n",
    "    max_size=int(parameters[\"MAX_SIZE\"]),\n",
    "    image_mean=ast.literal_eval(parameters[\"IMG_MEAN\"]),\n",
    "    image_std=ast.literal_eval(parameters[\"IMG_STD\"]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ada9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color mapping\n",
    "color_mapping = {\n",
    "    1: \"red\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcea34a-aeb6-4ca2-9208-ac71074819b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dataset\n",
    "datasetviewer = ObjectDetectionViewerSingle(\n",
    "    dataset=dataset, color_mapping=color_mapping, rcnn_transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277d891-0926-4005-938f-a8caf9646ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model from neptune or load from checkpoint\n",
    "if params[\"DOWNLOAD\"]:\n",
    "    download_path = pathlib.Path(os.getcwd()) / params[\"DOWNLOAD_PATH\"]\n",
    "    download_path.mkdir(parents=True, exist_ok=True)\n",
    "    model_name = \"best_model.pt\"  # that's how I called the best model\n",
    "    # model_name = properties['checkpoint_name']  # logged when called log_model_neptune()\n",
    "    if not (download_path / model_name).is_file():\n",
    "        experiment.download_artifact(\n",
    "            path=model_name, destination_dir=download_path\n",
    "        )  # download model\n",
    "\n",
    "    model_state_dict = torch.load(\n",
    "        download_path / model_name, map_location=torch.device(\"cpu\")\n",
    "    )\n",
    "else:\n",
    "    checkpoint = torch.load(params[\"MODEL_DIR\"], map_location=torch.device(\"cpu\"))\n",
    "    model_state_dict = checkpoint[\"hyper_parameters\"][\"model\"].state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a78b32-2283-45ad-83c2-11337e4c2505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes/learnspace/PyTorch-Object-Detection-Faster-RCNN-Tutorial/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/johannes/learnspace/PyTorch-Object-Detection-Faster-RCNN-Tutorial/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = get_faster_rcnn_resnet(\n",
    "    num_classes=int(parameters[\"CLASSES\"]),\n",
    "    backbone_name=ResNetBackbones(parameters[\"BACKBONE\"]),  # reverse look-up enum\n",
    "    anchor_size=ast.literal_eval(parameters[\"ANCHOR_SIZE\"]),\n",
    "    aspect_ratios=ast.literal_eval(parameters[\"ASPECT_RATIOS\"]),\n",
    "    fpn=ast.literal_eval(parameters[\"FPN\"]),\n",
    "    min_size=int(parameters[\"MIN_SIZE\"]),\n",
    "    max_size=int(parameters[\"MAX_SIZE\"]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d659f25-0d7d-4a97-be15-5795e24f2e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59d69e-b9ca-45b3-8320-2a7d4a0e4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference (cpu)\n",
    "model.eval()\n",
    "for sample in dataloader_prediction:\n",
    "    x, x_name = sample\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        pred = {key: value.numpy() for key, value in pred[0].items()}\n",
    "        name = pathlib.Path(x_name[0])\n",
    "        save_dir = pathlib.Path(os.getcwd()) / params[\"PREDICTIONS_PATH\"]\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pred_list = {\n",
    "            key: value.tolist() for key, value in pred.items()\n",
    "        }  # numpy arrays are not serializable -> .tolist()\n",
    "        save_json(pred_list, path=save_dir / name.with_suffix(\".json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2e424-4308-4586-a2ca-d0349cffc594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:16:23 - INFO - utils.py:27:get_filenames_of_path - Found 8 files in /Users/johannes/learnspace/PyTorch-Object-Detection-Faster-RCNN-Tutorial/predictions\n"
     ]
    }
   ],
   "source": [
    "# get prediction files\n",
    "predictions = get_filenames_of_path(\n",
    "    pathlib.Path(os.getcwd()) / params[\"PREDICTIONS_PATH\"]\n",
    ")\n",
    "predictions.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66697a0b-7989-4e44-8056-b62b70a49bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction dataset\n",
    "iou_threshold = 0.25\n",
    "score_threshold = 0.6\n",
    "\n",
    "transforms_prediction = ComposeDouble(\n",
    "    [\n",
    "        FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "        FunctionWrapperDouble(\n",
    "            apply_nms, input=False, target=True, iou_threshold=iou_threshold\n",
    "        ),\n",
    "        FunctionWrapperDouble(\n",
    "            apply_score_threshold,\n",
    "            input=False,\n",
    "            target=True,\n",
    "            score_threshold=score_threshold,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_prediction = ObjectDetectionDataSet(\n",
    "    inputs=inputs, targets=predictions, transform=transforms_prediction, use_cache=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb62e53-0e06-4bb5-86a3-8c23d1556ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "color_mapping = {\n",
    "    1: \"red\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50e474-202d-48ac-b5d0-13d69c3b7de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:16:25 - INFO - object_detection_viewer.py:42:get_data - Input sample: 001.jpg\n",
      "Shape: torch.Size([3, 300, 600])\n",
      "2023-06-08 18:16:25 - INFO - object_detection_viewer.py:64:get_target - Target sample: 001.json\n",
      "{'boxes': tensor([[334,  72, 425, 210],\n",
      "        [417,  17, 555, 172],\n",
      "        [ 53,   2, 168, 115],\n",
      "        [ 57, 106, 152, 233],\n",
      "        [186,  61, 253, 164],\n",
      "        [220,  43, 309, 152]]), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0, 0])}\n",
      "2023-06-08 18:16:26 - INFO - object_detection_viewer.py:42:get_data - Input sample: 002.jpg\n",
      "Shape: torch.Size([3, 900, 1200])\n",
      "2023-06-08 18:16:26 - INFO - object_detection_viewer.py:64:get_target - Target sample: 002.json\n",
      "{'boxes': tensor([[ 148,    0,  411,  301],\n",
      "        [ 763,   88,  965,  298],\n",
      "        [ 545,   71,  770,  329],\n",
      "        [ 572,  329,  848,  670],\n",
      "        [ 854,  277, 1145,  633],\n",
      "        [ 214,  370,  604,  900],\n",
      "        [  36,  439,  267,  754]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0, 0, 0])}\n",
      "2023-06-08 18:16:28 - INFO - object_detection_viewer.py:42:get_data - Input sample: 003.jpg\n",
      "Shape: torch.Size([3, 630, 1200])\n",
      "2023-06-08 18:16:28 - INFO - object_detection_viewer.py:64:get_target - Target sample: 003.json\n",
      "{'boxes': tensor([[ 297,  204,  549,  508],\n",
      "        [ 547,  181,  848,  515],\n",
      "        [ 303,    0,  557,  207],\n",
      "        [ 660,    0,  901,  173],\n",
      "        [ 738,  318, 1004,  558]]), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0])}\n",
      "2023-06-08 18:16:29 - INFO - object_detection_viewer.py:42:get_data - Input sample: 004.jpg\n",
      "Shape: torch.Size([3, 770, 1024])\n",
      "2023-06-08 18:16:29 - INFO - object_detection_viewer.py:64:get_target - Target sample: 004.json\n",
      "{'boxes': tensor([[ 550,   96,  767,  356],\n",
      "        [  52,  174,  151,  302],\n",
      "        [ 217,  174,  355,  344],\n",
      "        [ 344,  147,  498,  310],\n",
      "        [ 810,   70, 1024,  502]]), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0])}\n",
      "2023-06-08 18:16:30 - INFO - object_detection_viewer.py:42:get_data - Input sample: 005.jpg\n",
      "Shape: torch.Size([3, 480, 640])\n",
      "2023-06-08 18:16:30 - INFO - object_detection_viewer.py:64:get_target - Target sample: 005.json\n",
      "{'boxes': tensor([[ 51, 202, 203, 380],\n",
      "        [232,  80, 316, 169],\n",
      "        [420, 204, 555, 341],\n",
      "        [219, 202, 395, 450],\n",
      "        [ 13,  37, 152, 207],\n",
      "        [370, 101, 458, 180]]), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0, 0])}\n",
      "2023-06-08 18:16:30 - INFO - object_detection_viewer.py:42:get_data - Input sample: 006.jpg\n",
      "Shape: torch.Size([3, 912, 1368])\n",
      "2023-06-08 18:16:30 - INFO - object_detection_viewer.py:64:get_target - Target sample: 006.json\n",
      "{'boxes': tensor([[323, 111, 712, 665]]), 'labels': tensor([1]), 'scores': tensor([0])}\n",
      "2023-06-08 18:16:31 - INFO - object_detection_viewer.py:42:get_data - Input sample: 007.jpg\n",
      "Shape: torch.Size([3, 1500, 1085])\n",
      "2023-06-08 18:16:31 - INFO - object_detection_viewer.py:64:get_target - Target sample: 007.json\n",
      "{'boxes': tensor([], dtype=torch.int64), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], dtype=torch.int64)}\n",
      "2023-06-08 18:16:32 - INFO - object_detection_viewer.py:42:get_data - Input sample: 000.jpg\n",
      "Shape: torch.Size([3, 408, 612])\n",
      "2023-06-08 18:16:32 - INFO - object_detection_viewer.py:64:get_target - Target sample: 000.json\n",
      "{'boxes': tensor([[137,  74, 269, 231],\n",
      "        [512,  78, 612, 195],\n",
      "        [233,  65, 368, 196],\n",
      "        [  0, 129, 144, 294],\n",
      "        [380,  41, 497, 182]]), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0])}\n",
      "2023-06-08 18:16:33 - INFO - object_detection_viewer.py:42:get_data - Input sample: 007.jpg\n",
      "Shape: torch.Size([3, 1500, 1085])\n",
      "2023-06-08 18:16:33 - INFO - object_detection_viewer.py:64:get_target - Target sample: 007.json\n",
      "{'boxes': tensor([], dtype=torch.int64), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], dtype=torch.int64)}\n",
      "2023-06-08 18:16:33 - INFO - object_detection_viewer.py:42:get_data - Input sample: 000.jpg\n",
      "Shape: torch.Size([3, 408, 612])\n",
      "2023-06-08 18:16:33 - INFO - object_detection_viewer.py:64:get_target - Target sample: 000.json\n",
      "{'boxes': tensor([[137,  74, 269, 231],\n",
      "        [512,  78, 612, 195],\n",
      "        [233,  65, 368, 196],\n",
      "        [  0, 129, 144, 294],\n",
      "        [380,  41, 497, 182]]), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0])}\n",
      "2023-06-08 18:16:34 - INFO - object_detection_viewer.py:42:get_data - Input sample: 001.jpg\n",
      "Shape: torch.Size([3, 300, 600])\n",
      "2023-06-08 18:16:35 - INFO - object_detection_viewer.py:64:get_target - Target sample: 001.json\n",
      "{'boxes': tensor([[334,  72, 425, 210],\n",
      "        [417,  17, 555, 172],\n",
      "        [ 53,   2, 168, 115],\n",
      "        [ 57, 106, 152, 233],\n",
      "        [186,  61, 253, 164],\n",
      "        [220,  43, 309, 152]]), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0, 0])}\n",
      "2023-06-08 18:16:35 - INFO - object_detection_viewer.py:42:get_data - Input sample: 000.jpg\n",
      "Shape: torch.Size([3, 408, 612])\n",
      "2023-06-08 18:16:35 - INFO - object_detection_viewer.py:64:get_target - Target sample: 000.json\n",
      "{'boxes': tensor([[137,  74, 269, 231],\n",
      "        [512,  78, 612, 195],\n",
      "        [233,  65, 368, 196],\n",
      "        [  0, 129, 144, 294],\n",
      "        [380,  41, 497, 182]]), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0])}\n",
      "2023-06-08 18:16:36 - INFO - object_detection_viewer.py:42:get_data - Input sample: 001.jpg\n",
      "Shape: torch.Size([3, 300, 600])\n",
      "2023-06-08 18:16:36 - INFO - object_detection_viewer.py:64:get_target - Target sample: 001.json\n",
      "{'boxes': tensor([[334,  72, 425, 210],\n",
      "        [417,  17, 555, 172],\n",
      "        [ 53,   2, 168, 115],\n",
      "        [ 57, 106, 152, 233],\n",
      "        [186,  61, 253, 164],\n",
      "        [220,  43, 309, 152]]), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "# visualize predictions\n",
    "datasetviewer_prediction = ObjectDetectionViewer(\n",
    "    dataset=dataset_prediction, color_mapping=color_mapping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b26ebc-1df1-4829-9e72-1bd2452976e7",
   "metadata": {},
   "source": [
    "## Experiment with Non-maximum suppression (nms) and score-thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b440cbf-94fa-439c-ac9f-134959617f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## currently not available"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
